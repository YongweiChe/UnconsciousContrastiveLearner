{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9fa062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yongweic/.conda/envs/contrastive2/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/yongweic/.conda/envs/contrastive2/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/yongweic/.conda/envs/contrastive2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-06 13:42:48.554367: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yongweic/.conda/envs/jax-gpu/lib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from run_trial import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0d5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to CSV generated by experiments\n",
    "CSV_PATH = ''\n",
    "df = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc242d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_penalty = 0.00\n",
    "\n",
    "path = df.loc[(df['trial']==13) \n",
    "              & (df['feature_dim'] == 8) \n",
    "              & (df['temperature'] == 0.01)\n",
    "              & (df['l2_penalty'] ==l2_penalty)\n",
    "              , ['experimentInfo_path']].reset_index(drop=True)['experimentInfo_path'][0]\n",
    "print(path)\n",
    "\n",
    "\n",
    "# Define line types for different model types\n",
    "LSE_linestyle = '--'\n",
    "direct_linestyle = '-'\n",
    "\n",
    "# Define colors for LSE and direct models\n",
    "colors = ['grey', 'red', 'blue', 'green', 'black']\n",
    "\n",
    "\n",
    "# Open and read the pickle file\n",
    "with open(path, 'rb') as file:\n",
    "    experimentInfo = pickle.load(file)\n",
    "\n",
    "# Now, experimentInfo contains the object that was pickled at the specified path\n",
    "# You can access its attributes or data as needed, for example:\n",
    "distribution, models, accuracies = experimentInfo\n",
    "\n",
    "for model_type, acc in accuracies.items():\n",
    "    if 'norm' in model_type:\n",
    "        model_idx = 0\n",
    "    elif 'dist' in model_type:\n",
    "        model_idx = 1\n",
    "    elif 'dot' in model_type:\n",
    "        model_idx = 2\n",
    "    elif 'unconnected' in model_type:\n",
    "        model_idx = 3\n",
    "    else:\n",
    "        model_idx = 4\n",
    "\n",
    "    color = colors[model_idx]\n",
    "\n",
    "    if 'LSE' in model_type:\n",
    "        linestyle = LSE_linestyle\n",
    "    elif 'Direct' in model_type:\n",
    "        linestyle = direct_linestyle\n",
    "\n",
    "    if model_type == 'conscious_model':\n",
    "        plt.plot(acc,label='conscious', color=color)\n",
    "    else:\n",
    "        plt.plot([x[0] for x in acc], label=(f'{model_type} (Direct)'), color=color, linestyle='-')\n",
    "        plt.plot([x[1] for x in acc], label=(f'{model_type} LSE'), color=color, linestyle='--')\n",
    "    \n",
    "plt.title(f'Validation Accuracy of InfoNCE Models')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b50775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is defined and contains the necessary columns\n",
    "# l2_penalty, path, etc. are defined as given\n",
    "\n",
    "l2_penalty = 0.00\n",
    "\n",
    "# This path assignment is based on the original code provided\n",
    "path = df.loc[(df['trial']==13) \n",
    "              & (df['feature_dim'] == 8) \n",
    "              & (df['temperature'] == 0.01)\n",
    "              & (df['l2_penalty'] == l2_penalty)\n",
    "              , ['experimentInfo_path']].reset_index(drop=True)['experimentInfo_path'][0]\n",
    "print(path)\n",
    "\n",
    "# Define line types for different model types\n",
    "LSE_linestyle = '--'\n",
    "direct_linestyle = '-'\n",
    "\n",
    "# Define colors for LSE and direct models\n",
    "colors = ['grey', 'red', 'blue', 'green', 'black']\n",
    "\n",
    "# Open and read the pickle file\n",
    "with open(path, 'rb') as file:\n",
    "    experimentInfo = pickle.load(file)\n",
    "\n",
    "# Extract data from experimentInfo\n",
    "distribution, models, accuracies = experimentInfo\n",
    "\n",
    "# Initialize a dictionary to hold accuracies for each model type across trials\n",
    "all_accuracies = {model_type: [] for model_type in accuracies.keys()}\n",
    "\n",
    "# Simulate the data structure by appending each trial's accuracies to the respective list\n",
    "for trial in range(20):  # Assuming 20 trials labelled 0-19\n",
    "    for model_type, acc in accuracies.items():\n",
    "        all_accuracies[model_type].append(acc)\n",
    "\n",
    "# Calculate mean and std deviation for each model type\n",
    "mean_accuracies = {}\n",
    "std_accuracies = {}\n",
    "\n",
    "for model_type, acc_list in all_accuracies.items():\n",
    "    acc_array = np.array(acc_list)\n",
    "    mean_accuracies[model_type] = np.mean(acc_array, axis=0)\n",
    "    std_accuracies[model_type] = np.std(acc_array, axis=0)\n",
    "\n",
    "# Plotting the mean accuracies with error bars\n",
    "for model_type, mean_acc in mean_accuracies.items():\n",
    "    std_acc = std_accuracies[model_type]\n",
    "    \n",
    "    if 'norm' in model_type:\n",
    "        model_idx = 0\n",
    "    elif 'dist' in model_type:\n",
    "        model_idx = 1\n",
    "    elif 'dot' in model_type:\n",
    "        model_idx = 2\n",
    "    elif 'unconnected' in model_type:\n",
    "        model_idx = 3\n",
    "    else:\n",
    "        model_idx = 4\n",
    "\n",
    "    color = colors[model_idx]\n",
    "\n",
    "    if 'LSE' in model_type:\n",
    "        linestyle = LSE_linestyle\n",
    "    elif 'Direct' in model_type:\n",
    "        linestyle = direct_linestyle\n",
    "\n",
    "    if model_type == 'conscious_model':\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc, yerr=std_acc, label='conscious', color=color, linestyle=direct_linestyle)\n",
    "    else:\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 0], yerr=std_acc[:, 0], label=(f'{model_type} (Direct)'), color=color, linestyle='-')\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 1], yerr=std_acc[:, 1], label=(f'{model_type} LSE'), color=color, linestyle='--')\n",
    "\n",
    "plt.title('Validation Accuracy of InfoNCE Models')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is already defined and contains the necessary columns\n",
    "# l2_penalty, feature_dim, temperature, etc. are defined as given\n",
    "\n",
    "l2_penalty = 0.00\n",
    "\n",
    "# Collect all paths for the trials\n",
    "paths = df.loc[(df['feature_dim'] == 8) \n",
    "               & (df['temperature'] == 0.01) \n",
    "               & (df['l2_penalty'] == l2_penalty), \n",
    "               ['trial', 'experimentInfo_path']].sort_values('trial')['experimentInfo_path']\n",
    "\n",
    "# Define line types for different model types\n",
    "LSE_linestyle = '--'\n",
    "direct_linestyle = '-'\n",
    "\n",
    "# Define colors for LSE and direct models\n",
    "colors = ['grey', 'red', 'blue', 'green', 'black']\n",
    "\n",
    "# Initialize a dictionary to hold accuracies for each model type across trials\n",
    "all_accuracies = {}\n",
    "\n",
    "# Loop over each path and extract accuracies\n",
    "for path in paths:\n",
    "    with open(path, 'rb') as file:\n",
    "        experimentInfo = pickle.load(file)\n",
    "    # Extract data from experimentInfo\n",
    "    _, _, accuracies = experimentInfo\n",
    "    # Append accuracies to all_accuracies dictionary\n",
    "    for model_type, acc in accuracies.items():\n",
    "        if model_type not in all_accuracies:\n",
    "            all_accuracies[model_type] = []\n",
    "        all_accuracies[model_type].append(acc)\n",
    "\n",
    "# Calculate mean and std deviation for each model type\n",
    "mean_accuracies = {}\n",
    "std_accuracies = {}\n",
    "\n",
    "for model_type, acc_list in all_accuracies.items():\n",
    "    acc_array = np.array(acc_list)\n",
    "    mean_accuracies[model_type] = np.mean(acc_array, axis=0)\n",
    "    std_accuracies[model_type] = np.std(acc_array, axis=0)\n",
    "\n",
    "# Plotting the mean accuracies with error bars\n",
    "for model_type, mean_acc in mean_accuracies.items():\n",
    "    std_acc = std_accuracies[model_type]\n",
    "    \n",
    "    if 'norm' in model_type:\n",
    "        model_idx = 0\n",
    "    elif 'dist' in model_type:\n",
    "        model_idx = 1\n",
    "    elif 'dot' in model_type:\n",
    "        model_idx = 2\n",
    "    elif 'unconnected' in model_type:\n",
    "        model_idx = 3\n",
    "    else:\n",
    "        model_idx = 4\n",
    "\n",
    "    color = colors[model_idx]\n",
    "\n",
    "    if 'LSE' in model_type:\n",
    "        linestyle = LSE_linestyle\n",
    "    elif 'Direct' in model_type:\n",
    "        linestyle = direct_linestyle\n",
    "\n",
    "    if model_type == 'conscious_model':\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc, yerr=std_acc, label='conscious', color=color, linestyle=direct_linestyle)\n",
    "    else:\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 0], yerr=std_acc[:, 0], label=(f'{model_type} (Direct)'), color=color, linestyle='-')\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 1], yerr=std_acc[:, 1], label=(f'{model_type} LSE'), color=color, linestyle='--')\n",
    "\n",
    "plt.title('Validation Accuracy of InfoNCE Models')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is already defined and contains the necessary columns\n",
    "# l2_penalty, feature_dim, temperature, etc. are defined as given\n",
    "\n",
    "l2_penalty = 0.00\n",
    "\n",
    "# Collect all paths for the trials\n",
    "paths = df.loc[(df['feature_dim'] == 8) \n",
    "               & (df['temperature'] == 0.01) \n",
    "               & (df['l2_penalty'] == l2_penalty), \n",
    "               ['trial', 'experimentInfo_path']].sort_values('trial')['experimentInfo_path']\n",
    "\n",
    "# Define line types for different model types\n",
    "LSE_linestyle = '--'\n",
    "direct_linestyle = '-'\n",
    "\n",
    "# Define colors for LSE and direct models\n",
    "colors = ['grey', 'red', 'blue', 'green', 'black']\n",
    "\n",
    "# Initialize a dictionary to hold accuracies for each model type across trials\n",
    "all_accuracies = {}\n",
    "\n",
    "# Loop over each path and extract accuracies\n",
    "for path in paths:\n",
    "    with open(path, 'rb') as file:\n",
    "        experimentInfo = pickle.load(file)\n",
    "    # Extract data from experimentInfo\n",
    "    _, _, accuracies = experimentInfo\n",
    "    # Append accuracies to all_accuracies dictionary\n",
    "    for model_type, acc in accuracies.items():\n",
    "        if model_type not in all_accuracies:\n",
    "            all_accuracies[model_type] = []\n",
    "        all_accuracies[model_type].append(acc)\n",
    "\n",
    "# Calculate mean and std deviation for each model type\n",
    "mean_accuracies = {}\n",
    "std_accuracies = {}\n",
    "\n",
    "for model_type, acc_list in all_accuracies.items():\n",
    "    acc_array = np.array(acc_list)\n",
    "    mean_accuracies[model_type] = np.mean(acc_array, axis=0)\n",
    "    std_accuracies[model_type] = np.std(acc_array, axis=0)\n",
    "\n",
    "# Plotting the mean accuracies with error bars\n",
    "for model_type, mean_acc in mean_accuracies.items():\n",
    "    std_acc = std_accuracies[model_type]\n",
    "    \n",
    "    if 'norm' in model_type:\n",
    "        model_idx = 0\n",
    "    elif 'dist' in model_type:\n",
    "        model_idx = 1\n",
    "    elif 'dot' in model_type:\n",
    "        model_idx = 2\n",
    "    elif 'unconnected' in model_type:\n",
    "        model_idx = 3\n",
    "    else:\n",
    "        model_idx = 4\n",
    "\n",
    "    color = colors[model_idx]\n",
    "\n",
    "    if 'LSE' in model_type:\n",
    "        linestyle = LSE_linestyle\n",
    "    elif 'Direct' in model_type:\n",
    "        linestyle = direct_linestyle\n",
    "\n",
    "    if model_type == 'conscious_model':\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc, yerr=std_acc, label='Ground Truth', color=color, linestyle=direct_linestyle)\n",
    "    elif model_type == 'unconnected_model':\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 0], yerr=std_acc[:, 0], label=(f'Unconnected (Direct)'), color='green', linestyle='-')\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 1], yerr=std_acc[:, 1], label=(f'Unconnected (Monte Carlo)'), color='darkgreen', linestyle='--')\n",
    "\n",
    "plt.title('Validation Accuracy of Unconnected Model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0976b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is already defined and contains the necessary columns\n",
    "# l2_penalty, feature_dim, temperature, etc. are defined as given\n",
    "\n",
    "l2_penalty = 0.00\n",
    "\n",
    "# Collect all paths for the trials\n",
    "paths = df.loc[(df['feature_dim'] == 16) \n",
    "               & (df['temperature'] == 0.01) \n",
    "               & (df['l2_penalty'] == l2_penalty), \n",
    "               ['trial', 'experimentInfo_path']].sort_values('trial')['experimentInfo_path']\n",
    "\n",
    "# Define line types for different model types\n",
    "LSE_linestyle = '--'\n",
    "direct_linestyle = '-'\n",
    "\n",
    "# Define colors for LSE and direct models\n",
    "colors = ['grey', 'red', 'blue', 'green', 'black']\n",
    "\n",
    "# Initialize a dictionary to hold accuracies for each model type across trials\n",
    "all_accuracies = {}\n",
    "\n",
    "# Loop over each path and extract accuracies\n",
    "for path in paths:\n",
    "    with open(path, 'rb') as file:\n",
    "        experimentInfo = pickle.load(file)\n",
    "    # Extract data from experimentInfo\n",
    "    _, _, accuracies = experimentInfo\n",
    "    # Append accuracies to all_accuracies dictionary\n",
    "    for model_type, acc in accuracies.items():\n",
    "        if model_type not in all_accuracies:\n",
    "            all_accuracies[model_type] = []\n",
    "        all_accuracies[model_type].append(acc)\n",
    "\n",
    "# Calculate mean and std deviation for each model type\n",
    "mean_accuracies = {}\n",
    "std_accuracies = {}\n",
    "\n",
    "for model_type, acc_list in all_accuracies.items():\n",
    "    acc_array = np.array(acc_list)\n",
    "    mean_accuracies[model_type] = np.mean(acc_array, axis=0)\n",
    "    std_accuracies[model_type] = np.std(acc_array, axis=0)\n",
    "\n",
    "# Plotting the mean accuracies with error bars\n",
    "for model_type, mean_acc in mean_accuracies.items():\n",
    "    std_acc = std_accuracies[model_type]\n",
    "    \n",
    "    if 'norm' in model_type:\n",
    "        model_idx = 0\n",
    "    elif 'dist' in model_type:\n",
    "        model_idx = 1\n",
    "    elif 'dot' in model_type:\n",
    "        model_idx = 2\n",
    "    elif 'unconnected' in model_type:\n",
    "        model_idx = 3\n",
    "    else:\n",
    "        model_idx = 4\n",
    "\n",
    "    color = colors[model_idx]\n",
    "\n",
    "    if 'LSE' in model_type:\n",
    "        linestyle = LSE_linestyle\n",
    "    elif 'Direct' in model_type:\n",
    "        linestyle = direct_linestyle\n",
    "\n",
    "    if model_type == 'conscious_model':\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc, yerr=std_acc, label='Ground Truth', color=color, linestyle=direct_linestyle)\n",
    "    elif model_type == 'dist_model':\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 0], yerr=std_acc[:, 0], label=(f'L2 Dist (Direct)'), color=color, linestyle='-')\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 1], yerr=std_acc[:, 1], label=(f'L2 Dist (Monte Carlo)'), color='orange', linestyle='--')\n",
    "#     elif model_type == 'norm_model':\n",
    "#         plt.errorbar(range(len(mean_acc)), mean_acc[:, 0], yerr=std_acc[:, 0], label=(f'Normed Dot Product (Direct)'), color='purple', linestyle='-')\n",
    "#         plt.errorbar(range(len(mean_acc)), mean_acc[:, 1], yerr=std_acc[:, 1], label=(f'Normed Dot Product (Monte Carlo)'), color='indigo', linestyle='--')\n",
    "\n",
    "plt.title('Validation Accuracy of L2 Dist Model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is already defined and contains the necessary columns\n",
    "# l2_penalty, feature_dim, temperature, etc. are defined as given\n",
    "\n",
    "l2_penalty = 0.00\n",
    "\n",
    "# Collect all paths for the trials\n",
    "paths = df.loc[(df['feature_dim'] == 8) \n",
    "               & (df['temperature'] == 0.01) \n",
    "               & (df['l2_penalty'] == l2_penalty), \n",
    "               ['trial', 'experimentInfo_path']].sort_values('trial')['experimentInfo_path']\n",
    "\n",
    "# Define line types for different model types\n",
    "LSE_linestyle = '--'\n",
    "direct_linestyle = '-'\n",
    "\n",
    "# Define colors for LSE and direct models\n",
    "colors = ['grey', 'red', 'blue', 'green', 'black']\n",
    "\n",
    "# Initialize a dictionary to hold accuracies for each model type across trials\n",
    "all_accuracies = {}\n",
    "\n",
    "# Loop over each path and extract accuracies\n",
    "for path in paths:\n",
    "    with open(path, 'rb') as file:\n",
    "        experimentInfo = pickle.load(file)\n",
    "    # Extract data from experimentInfo\n",
    "    _, _, accuracies = experimentInfo\n",
    "    # Append accuracies to all_accuracies dictionary\n",
    "    for model_type, acc in accuracies.items():\n",
    "        if model_type not in all_accuracies:\n",
    "            all_accuracies[model_type] = []\n",
    "        all_accuracies[model_type].append(acc)\n",
    "\n",
    "# Calculate mean and std deviation for each model type\n",
    "mean_accuracies = {}\n",
    "std_accuracies = {}\n",
    "\n",
    "for model_type, acc_list in all_accuracies.items():\n",
    "    acc_array = np.array(acc_list)\n",
    "    mean_accuracies[model_type] = np.mean(acc_array, axis=0)\n",
    "    std_accuracies[model_type] = np.std(acc_array, axis=0)\n",
    "\n",
    "# Plotting the mean accuracies with error bars\n",
    "for model_type, mean_acc in mean_accuracies.items():\n",
    "    std_acc = std_accuracies[model_type]\n",
    "    \n",
    "    if 'norm' in model_type:\n",
    "        model_idx = 0\n",
    "    elif 'dist' in model_type:\n",
    "        model_idx = 1\n",
    "    elif 'dot' in model_type:\n",
    "        model_idx = 2\n",
    "    elif 'unconnected' in model_type:\n",
    "        model_idx = 3\n",
    "    else:\n",
    "        model_idx = 4\n",
    "\n",
    "    color = colors[model_idx]\n",
    "\n",
    "    if 'LSE' in model_type:\n",
    "        linestyle = LSE_linestyle\n",
    "    elif 'Direct' in model_type:\n",
    "        linestyle = direct_linestyle\n",
    "\n",
    "    if model_type == 'conscious_model':\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc, yerr=std_acc, label='Ground Truth', color=color, linestyle=direct_linestyle)\n",
    "#     elif model_type == 'dist_model':\n",
    "#         plt.errorbar(range(len(mean_acc)), mean_acc[:, 0], yerr=std_acc[:, 0], label=(f'L2 Dist (Direct)'), color=color, linestyle='-')\n",
    "#         plt.errorbar(range(len(mean_acc)), mean_acc[:, 1], yerr=std_acc[:, 1], label=(f'L2 Dist (Monte Carlo)'), color='orange', linestyle='--')\n",
    "    elif model_type == 'norm_model':\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 0], yerr=std_acc[:, 0], label=(f'Normed Dot Product (Direct)'), color='purple', linestyle='-')\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 1], yerr=std_acc[:, 1], label=(f'Normed Dot Product (Monte Carlo)'), color='indigo', linestyle='--')\n",
    "\n",
    "plt.title('Validation Accuracy of Normed Dot Model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b432fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is already defined and contains the necessary columns\n",
    "# l2_penalty, feature_dim, temperature, etc. are defined as given\n",
    "\n",
    "l2_penalty = 0.00\n",
    "\n",
    "# Collect all paths for the trials\n",
    "paths = df.loc[(df['feature_dim'] == 8) \n",
    "               & (df['temperature'] == 0.01) \n",
    "               & (df['l2_penalty'] == l2_penalty), \n",
    "               ['trial', 'experimentInfo_path']].sort_values('trial')['experimentInfo_path']\n",
    "\n",
    "# Define line types for different model types\n",
    "LSE_linestyle = '--'\n",
    "direct_linestyle = '-'\n",
    "\n",
    "# Define colors for LSE and direct models\n",
    "colors = ['grey', 'red', 'blue', 'green', 'black']\n",
    "\n",
    "# Initialize a dictionary to hold accuracies for each model type across trials\n",
    "all_accuracies = {}\n",
    "\n",
    "# Loop over each path and extract accuracies\n",
    "for path in paths:\n",
    "    with open(path, 'rb') as file:\n",
    "        experimentInfo = pickle.load(file)\n",
    "    # Extract data from experimentInfo\n",
    "    _, _, accuracies = experimentInfo\n",
    "    # Append accuracies to all_accuracies dictionary\n",
    "    for model_type, acc in accuracies.items():\n",
    "        if model_type not in all_accuracies:\n",
    "            all_accuracies[model_type] = []\n",
    "        all_accuracies[model_type].append(acc)\n",
    "\n",
    "# Calculate mean and std deviation for each model type\n",
    "mean_accuracies = {}\n",
    "std_accuracies = {}\n",
    "\n",
    "for model_type, acc_list in all_accuracies.items():\n",
    "    acc_array = np.array(acc_list)\n",
    "    mean_accuracies[model_type] = np.mean(acc_array, axis=0)\n",
    "    std_accuracies[model_type] = np.std(acc_array, axis=0)\n",
    "\n",
    "# Plotting the mean accuracies with error bars\n",
    "for model_type, mean_acc in mean_accuracies.items():\n",
    "    std_acc = std_accuracies[model_type]\n",
    "    \n",
    "    if 'norm' in model_type:\n",
    "        model_idx = 0\n",
    "    elif 'dist' in model_type:\n",
    "        model_idx = 1\n",
    "    elif 'dot' in model_type:\n",
    "        model_idx = 2\n",
    "    elif 'unconnected' in model_type:\n",
    "        model_idx = 3\n",
    "    else:\n",
    "        model_idx = 4\n",
    "\n",
    "    color = colors[model_idx]\n",
    "\n",
    "    if 'LSE' in model_type:\n",
    "        linestyle = LSE_linestyle\n",
    "    elif 'Direct' in model_type:\n",
    "        linestyle = direct_linestyle\n",
    "\n",
    "    if model_type == 'conscious_model':\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc, yerr=std_acc, label='Ground Truth', color=color, linestyle=direct_linestyle)\n",
    "    elif model_type == 'dot_model':\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 0], yerr=std_acc[:, 0], label=(f'Dot Product (Direct)'), color=color, linestyle='-')\n",
    "        plt.errorbar(range(len(mean_acc)), mean_acc[:, 1], yerr=std_acc[:, 1], label=(f'Dot Product (Monte Carlo)'), color=color, linestyle='--')\n",
    "#     elif model_type == 'norm_model':\n",
    "#         plt.errorbar(range(len(mean_acc)), mean_acc[:, 0], yerr=std_acc[:, 0], label=(f'Normed Dot Product (Direct)'), color='purple', linestyle='-')\n",
    "#         plt.errorbar(range(len(mean_acc)), mean_acc[:, 1], yerr=std_acc[:, 1], label=(f'Normed Dot Product (Monte Carlo)'), color='indigo', linestyle='--')\n",
    "\n",
    "plt.title('Validation Accuracy of Dot Model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is already defined and contains the necessary columns\n",
    "# l2_penalty, feature_dim, temperature, etc. are defined as given\n",
    "\n",
    "l2_penalty = 0.00\n",
    "\n",
    "# Collect all paths for the trials\n",
    "paths = df.loc[(df['feature_dim'] == 8) \n",
    "               & (df['temperature'] == 0.01) \n",
    "               & (df['l2_penalty'] == l2_penalty), \n",
    "               ['trial', 'experimentInfo_path']].sort_values('trial')['experimentInfo_path']\n",
    "\n",
    "# Define line types for different model types\n",
    "LSE_linestyle = '--'\n",
    "direct_linestyle = '-'\n",
    "\n",
    "# Define colors for LSE and direct models\n",
    "colors = ['grey', 'red', 'blue', 'green', 'black']\n",
    "\n",
    "# Initialize a dictionary to hold accuracies for each model type across trials\n",
    "all_accuracies = {}\n",
    "\n",
    "# Loop over each path and extract accuracies\n",
    "for path in paths:\n",
    "    with open(path, 'rb') as file:\n",
    "        experimentInfo = pickle.load(file)\n",
    "    # Extract data from experimentInfo\n",
    "    _, _, accuracies = experimentInfo\n",
    "    # Append accuracies to all_accuracies dictionary\n",
    "    for model_type, acc in accuracies.items():\n",
    "        if model_type not in all_accuracies:\n",
    "            all_accuracies[model_type] = []\n",
    "        all_accuracies[model_type].append(acc)\n",
    "\n",
    "# Calculate mean and std deviation for each model type\n",
    "mean_accuracies = {}\n",
    "std_accuracies = {}\n",
    "\n",
    "for model_type, acc_list in all_accuracies.items():\n",
    "    acc_array = np.array(acc_list)\n",
    "    mean_accuracies[model_type] = np.mean(acc_array, axis=0)\n",
    "    std_accuracies[model_type] = np.std(acc_array, axis=0)\n",
    "\n",
    "# Plotting the mean accuracies with error bars and caps\n",
    "for model_type, mean_acc in mean_accuracies.items():\n",
    "    std_acc = std_accuracies[model_type]\n",
    "    \n",
    "    if 'norm' in model_type:\n",
    "        model_idx = 0\n",
    "    elif 'dist' in model_type:\n",
    "        model_idx = 1\n",
    "    elif 'dot' in model_type:\n",
    "        model_idx = 2\n",
    "    elif 'unconnected' in model_type:\n",
    "        model_idx = 3\n",
    "    else:\n",
    "        model_idx = 4\n",
    "\n",
    "    color = colors[model_idx]\n",
    "\n",
    "    if 'LSE' in model_type:\n",
    "        linestyle = LSE_linestyle\n",
    "    elif 'Direct' in model_type:\n",
    "        linestyle = direct_linestyle\n",
    "\n",
    "    epochs = range(len(mean_acc))\n",
    "\n",
    "    if model_type == 'conscious_model':\n",
    "        plt.errorbar(epochs, mean_acc, yerr=std_acc, label='conscious', color=color, linestyle=direct_linestyle, capsize=5)\n",
    "    elif model_type =='unconnected_model':\n",
    "        plt.errorbar(epochs, mean_acc[:, 0], yerr=std_acc[:, 0], label=(f'{model_type} (Direct)'), color=color, linestyle='-', capsize=5)\n",
    "        plt.errorbar(epochs, mean_acc[:, 1], yerr=std_acc[:, 1], label=(f'{model_type} LSE'), color=color, linestyle='--', capsize=5)\n",
    "\n",
    "plt.title('Validation Accuracy of InfoNCE Models')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best(acc):\n",
    "    if type(acc[0]) is tuple:\n",
    "        return max([x[0] for x in acc]), max([x[1] for x in acc])\n",
    "    else:\n",
    "        return max(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52265a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "temperatures = [0.001, 0.01]\n",
    "\n",
    "for temp in temperatures:\n",
    "    paths = df.loc[(df['trial']==0) & (df['feature_dim'] == 4) & (df['temperature'] == temp), ['experimentInfo_path', 'l2_penalty']].reset_index(drop=True)\n",
    "\n",
    "    penalties = []\n",
    "    performances = defaultdict(list)\n",
    "\n",
    "\n",
    "    for _, row in paths.iterrows():\n",
    "        penalty = row['l2_penalty']\n",
    "        penalties.append(penalty)\n",
    "        p = row['experimentInfo_path']\n",
    "\n",
    "        with open(p, 'rb') as file:\n",
    "            experimentInfo = pickle.load(file)\n",
    "\n",
    "        distribution, models, accuracies = experimentInfo\n",
    "\n",
    "        for model_type, acc in accuracies.items():\n",
    "            \n",
    "            if model_type == 'conscious_model':\n",
    "                performances[model_type].append(best(acc))\n",
    "            else:\n",
    "                direct, LSE = best(acc)\n",
    "                performances[f'{model_type} (Direct)'].append(direct)\n",
    "                performances[f'{model_type} (LSE)'].append(LSE)\n",
    "\n",
    "    print(performances)\n",
    "\n",
    "    # Convert numerical penalties to string labels to treat them as categorical\n",
    "    penalty_labels = [str(p) for p in penalties]\n",
    "\n",
    "    # Create a figure and axis for plotting\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for name, perf in performances.items():\n",
    "        # Generate a sequence of indices as x-coordinates for plotting\n",
    "        x_coords = range(len(perf))\n",
    "        # Plot using the generated x-coordinates and corresponding performance values\n",
    "        ax.plot(x_coords, perf, label=name, marker='o')  # Adding 'marker' to denote each data point\n",
    "\n",
    "        # Set the x-axis ticks to correspond to the penalty labels\n",
    "        ax.set_xticks(x_coords)\n",
    "        ax.set_xticklabels(penalty_labels, rotation=45)  # Rotate labels to avoid overlap\n",
    "\n",
    "    ax.set_xlabel('L2 Penalty')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    plt.title(f'Performance Across Different L2 Penalties w/ temp={temp}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()  # Adjust layout to make room for the rotated x-axis labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984b670",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define line types for different model types\n",
    "LSE_linestyle = '--'\n",
    "direct_linestyle = '-'\n",
    "\n",
    "# Define colors for LSE and direct models\n",
    "colors = ['grey', 'red', 'blue']\n",
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame already loaded with data\n",
    "temperatures = [0.001, 0.010]  # Example temperatures\n",
    "\n",
    "# Setting up a 2x3 grid for subplots\n",
    "fig, axs = plt.subplots(2, 3, figsize=(10, 10))  # Adjust the figure size as needed\n",
    "\n",
    "# Flatten the axs array for easy indexing\n",
    "axs = axs.flatten()\n",
    "acc_dict = defaultdict(lambda: 0)\n",
    "\n",
    "for t in range(10):\n",
    "    best_dict = defaultdict(lambda: 0)\n",
    "    for temp_index, temp in enumerate(temperatures):\n",
    "        paths = df.loc[(df['trial'] == t) \n",
    "                       & (df['feature_dim'] == 8) \n",
    "                       & (df['temperature'] == temp), ['experimentInfo_path', 'l2_penalty']].reset_index(drop=True)\n",
    "\n",
    "        penalties = []\n",
    "        performances = defaultdict(list)\n",
    "    \n",
    "        for _, row in paths.iterrows():\n",
    "            penalty = row['l2_penalty']\n",
    "            if penalty >= 0.5:\n",
    "                continue\n",
    "            penalties.append(penalty)\n",
    "            p = row['experimentInfo_path']\n",
    "\n",
    "            with open(p, 'rb') as file:\n",
    "                experimentInfo = pickle.load(file)\n",
    "\n",
    "            distribution, models, accuracies = experimentInfo\n",
    "\n",
    "            for model_type, acc in accuracies.items():\n",
    "                if model_type == 'conscious_model':\n",
    "                    performances[model_type].append(best(acc))\n",
    "                else:\n",
    "    #                 if model_type == 'norm_model':\n",
    "    #                     continue\n",
    "                    direct, LSE = best(acc)\n",
    "                    performances[f'{model_type} (Direct)'].append(direct)\n",
    "                    performances[f'{model_type} (LSE)'].append(LSE)\n",
    "\n",
    "        penalty_labels = [str(p) for p in penalties]\n",
    "        x_coords = range(len(penalty_labels))\n",
    "        \n",
    "        \n",
    "        for i, (name, perf) in enumerate(performances.items()):\n",
    "            best_dict[name] = max(best_dict[name], max(perf))\n",
    "            \n",
    "        \n",
    "\n",
    "        # Plot on the current subplot\n",
    "        ax = axs[temp_index]\n",
    "        for i, (name, perf) in enumerate(performances.items()):\n",
    "            if 'norm' in name:\n",
    "                model_idx = 0\n",
    "            elif 'dist' in name:\n",
    "                model_idx = 1\n",
    "            elif 'dot' in name:\n",
    "                model_idx = 2\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            color = colors[model_idx]\n",
    "\n",
    "            if 'LSE' in name:\n",
    "                linestyle = LSE_linestyle\n",
    "            elif 'Direct' in name:\n",
    "                linestyle = direct_linestyle\n",
    "\n",
    "            # linestyle = model_linestyles[model_idx]\n",
    "\n",
    "            ax.plot(x_coords, perf, label=name, marker='o', color=color, linestyle=linestyle)\n",
    "\n",
    "        ax.set_xticks(x_coords)\n",
    "        ax.set_xticklabels(penalty_labels, rotation=45)\n",
    "        ax.set_title(f'Temperature: {temp}')\n",
    "        ax.set_xlabel('L2 Penalty')\n",
    "        ax.set_ylabel('Performance')\n",
    "        ax.legend()\n",
    "    \n",
    "    print(best_dict)\n",
    "    for k, v in best_dict.items():\n",
    "        acc_dict[k] = acc_dict[k] + v\n",
    "    # If there are any unused subplots (in case of less than 6 temperatures), hide them\n",
    "    for i in range(len(temperatures), 6):\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(f'ACC DICT')\n",
    "print(acc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Feature Embedding = 4\n",
    "{'norm_model (Direct)': 8.334677419354838,\n",
    "             'norm_model (LSE)': 7.056451612903226,\n",
    "             'dist_model (Direct)': 9.179435483870966,\n",
    "             'dist_model (LSE)': 9.039314516129032,\n",
    "             'dot_model (Direct)': 1.9455645161290325,\n",
    "             'dot_model (LSE)': 6.94657258064516,\n",
    "             'unconnected_model (Direct)': 0.8306451612903226,\n",
    "             'unconnected_model (LSE)': 7.601814516129032,\n",
    "             'conscious_model': 9.194556451612902})\n",
    "Feature Embedding - 8\n",
    "{'norm_model (Direct)': 9.651209677419356,\n",
    "             'norm_model (LSE)': 7.56149193548387,\n",
    "             'dist_model (Direct)': 9.557459677419354,\n",
    "             'dist_model (LSE)': 9.495967741935486,\n",
    "             'dot_model (Direct)': 3.9627016129032255,\n",
    "             'dot_model (LSE)': 7.410282258064517,\n",
    "             'unconnected_model (Direct)': 0.779233870967742,\n",
    "             'unconnected_model (LSE)': 9.089717741935484,\n",
    "             'conscious_model': 9.703629032258064}\n",
    "\"\"\"\n",
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779bd42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Set figure size\n",
    "color_map = {'norm': 'orange', 'dist': 'skyblue', 'dot_': 'red', 'cons': 'gray', 'unco': 'green'}\n",
    "plt.figure(figsize=(12, 8))  # Adjust the values to make it wider\n",
    "\n",
    "# Create bar plot\n",
    "bars = plt.bar(acc_dict.keys(), [x / 10 for x in acc_dict.values()], width=0.6)\n",
    "\n",
    "# Function to darken a color\n",
    "def darken_color(color, factor=0.7):\n",
    "    # Convert color to RGB\n",
    "    rgb = mcolors.to_rgb(color)\n",
    "    # Darken the color by reducing brightness\n",
    "    return tuple([x * factor for x in rgb])\n",
    "\n",
    "# Color the bars and set edge color to a darker shade\n",
    "for bar, key in zip(bars, acc_dict.keys()):\n",
    "    color_code = key[:4]\n",
    "    if color_code in color_map:\n",
    "        main_color = color_map[color_code]\n",
    "        bar.set_color(main_color)\n",
    "        bar.set_edgecolor(darken_color(main_color))\n",
    "        bar.set_linewidth(4)\n",
    "    else:\n",
    "        # Use a default color if the first 4 digits don't match any in the color map\n",
    "        bar.set_color('gray')\n",
    "        bar.set_alpha(0.5)  # Make the default color semi-transparent\n",
    "        bar.set_edgecolor(darken_color('gray'))\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('InfoNCE Variants', fontsize=14)\n",
    "plt.ylabel('Retrieval Accuracy', fontsize=14)\n",
    "# plt.title('Accuracy of Differnt Variants of InfoNCE', fontsize=16)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate('{:.3f}'.format(height),\n",
    "                 xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                 xytext=(0, 3),\n",
    "                 textcoords=\"offset points\",\n",
    "                 ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add grid\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c7574",
   "metadata": {},
   "source": [
    "### Check embedding Gaussianity.\n",
    "\n",
    "Holding fixed feature dimension 2, for the grid temperatures x l2_penalty, what percentage of the embeddings are Gaussian?\n",
    "\n",
    "IMPORTANT: Want to highlight diff between Inner Product InfoNCE and L2 Distance InfoNCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f76e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg \n",
    "\n",
    "# TODO: code here, plot confusion matrix\n",
    "feature_dim = 2\n",
    "temps = [0.001, 0.01, 0.1, 1.]\n",
    "l2_penalties = [0.0, 0.001, 0.01, 0.1, 0.5]\n",
    "\n",
    "gaussian_grid_dot = np.zeros((len(temps), len(l2_penalties)))\n",
    "gaussian_grid_dist = np.zeros((len(temps), len(l2_penalties)))\n",
    "\n",
    "# IMPORTANT, CHANGE NOISE, for 128_run it is 2.5 2.5 for others it is 1.5 1.5\n",
    "for idx, temp in enumerate(temps):\n",
    "    print('temp')\n",
    "    for idy, l2_penalty in enumerate(l2_penalties):\n",
    "        print(f'{temp}, {l2_penalty}')\n",
    "        gaussian_counter = defaultdict(list)\n",
    "        \n",
    "        paths = df.loc[(df['feature_dim'] == feature_dim) \n",
    "                       & (df['temperature'] == temp)\n",
    "                       & (df['l2_penalty'] == l2_penalty)\n",
    "                       , ['experimentInfo_path', 'l2_penalty']].reset_index(drop=True)\n",
    "        plotted = False\n",
    "        for _, row in paths.iterrows():\n",
    "            p = row['experimentInfo_path']\n",
    "\n",
    "            with open(p, 'rb') as file:\n",
    "                experimentInfo = pickle.load(file)\n",
    "\n",
    "            distribution, models, accuracies = experimentInfo\n",
    "            \n",
    "            mu = distribution['mu']\n",
    "            Sigma = distribution['Sigma']\n",
    "            transform1 = distribution['transform1']\n",
    "            transform2 = distribution['transform2']\n",
    "            \n",
    "            DIMS = (mu.shape[0], transform1.shape[0], transform2.shape[0])\n",
    "            \n",
    "            cum_dims = [sum(DIMS[:i+1]) for i in range(len(DIMS))]\n",
    "            \n",
    "            val_set = JointGaussianDataset(mu, \n",
    "                                           Sigma,\n",
    "                                           transform1=transform1, \n",
    "                                           transform2=transform2, \n",
    "                                           pair=[0, 1], # unimportant\n",
    "                                           dims=DIMS, \n",
    "                                           num_points=1000, \n",
    "                                           noise=(2.5, 2.5))\n",
    "            \n",
    "            points = torch.tensor(val_set.points)\n",
    "            for model_type, model in models.items():\n",
    "                \n",
    "                PHI_B = model.encode(points[0:300, :cum_dims[0]], model.encoderA)\n",
    "                # Convert PHI_B to a NumPy array for compatibility with statistical tests\n",
    "                PHI_B_np = PHI_B.detach().numpy()\n",
    "                if not plotted and (model_type == 'dot_model' or model_type == 'dist_model' or model_type == 'norm_model'):\n",
    "                    plt.scatter(PHI_B_np[:, 0], PHI_B_np[:, 1], label=model_type)\n",
    "\n",
    "                # Perform the Henze-Zirkler multivariate normality test\n",
    "                hz_test = pg.multivariate_normality(PHI_B_np, alpha=.05)\n",
    "                # print(f\"Henze-Zirkler Test on PHI_B_dist: {hz_test}\")\n",
    "                if model_type == 'dist_model':\n",
    "                    gaussian_grid_dist[idx, idy] += hz_test.pval\n",
    "                elif model_type == 'dot_model':\n",
    "                    gaussian_grid_dot[idx, idy] += hz_test.pval\n",
    "                \n",
    "            plotted = True\n",
    "        plt.title(f'InfoNCE Embedding Distribution')\n",
    "        plt.xlabel('x_1')\n",
    "        plt.ylabel('x_2')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "print(len(paths))\n",
    "gaussian_grid_dot /= len(paths)\n",
    "gaussian_grid_dist /= len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(gaussian_grid_dist)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(gaussian_grid_dist[:4,:4], annot=True, cmap='Blues', xticklabels=l2_penalties[:4], yticklabels=temps)\n",
    "\n",
    "# Adding labels for axes\n",
    "plt.xlabel('l2 penalty')\n",
    "plt.ylabel('temperature')\n",
    "\n",
    "plt.title('Is L2 Dist InfoNCE Gaussian? (Average p-val)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2babe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "gaussian_grid_dot = np.nan_to_num(gaussian_grid_dot)\n",
    "print(gaussian_grid_dot)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(gaussian_grid_dot[:4,:4], annot=True, cmap='Blues', xticklabels=l2_penalties[:4], yticklabels=temps[:4])\n",
    "\n",
    "# Adding labels for axes\n",
    "plt.xlabel('l2 penalty')\n",
    "plt.ylabel('temperature')\n",
    "\n",
    "plt.title('Is Inner Product InfoNCE Gaussian? (Average p-val)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive2 [~/.conda/envs/contrastive2/]",
   "language": "python",
   "name": "conda_contrastive2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
