{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zF1hlA6YnV4I",
    "outputId": "99cb9b95-1eee-4d1e-fb48-9cd6e712c4fe"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/facebookresearch/ImageBind\n",
    "%cd ImageBind\n",
    "# remember to get rid of mayavi reguirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GRAi167u56i",
    "outputId": "db24b628-9acd-4d8c-abc4-e2afdc805f48"
   },
   "outputs": [],
   "source": [
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQGGvuB9gVmm",
    "outputId": "e4b118ce-43a3-40c4-e5ec-418b13af1170"
   },
   "outputs": [],
   "source": [
    "!pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NmmRKCmcuyR-",
    "outputId": "8a33823e-2e58-4571-c1a3-6033d0a7aa2c"
   },
   "outputs": [],
   "source": [
    "!pip install laion-clap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b8903893d76f4b0e889e271de0027597",
      "ffb0fcdc3b75424f96946c90b1000116",
      "95ec030e403d4c03b28be937a674b0aa",
      "545c1bab284e47eaad977fde7c5f0013",
      "701a4916b7c54e71b03a1b6eae6ef364",
      "41567679fc1448699707c486ffdc6df8",
      "1a38f63b85f94d1ab640b4d7120f9213",
      "4aa0727423fb4ac6b26209e7b46e1ebf",
      "e94fb3a33d394e5a8f286089b4b2c00a",
      "95a0b38d054843d5b29709a7a5a9c13e",
      "d831ce4624cf42a283ddbac9d9cb9956"
     ]
    },
    "id": "35nkYOIurL_n",
    "outputId": "349e39f4-1d6f-4c46-eef8-b186292bcc8f"
   },
   "outputs": [],
   "source": [
    "from imagebind import data\n",
    "import torch\n",
    "from imagebind.models import imagebind_model\n",
    "from imagebind.models.imagebind_model import ModalityType\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "ib_model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "ib_model.eval()\n",
    "ib_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "cd383711216e454f9ad8c8f88b4eb2b0",
      "97f4659b1b604989b2dfb32d75d702cd",
      "90ae8978682347b5aea74dc19318232b",
      "d8ab476a464944caa26c3eb196518c78",
      "00ad6be7495946068f7caf02676913b0",
      "73cf4181dbd74dfe9a64cac435449836",
      "dc2ff2709de6483dbda8c6eaa3d8de74",
      "2ef52e6441604606a2eb1a96e6eb4e39",
      "0ad70ac71b984582be1a712ae82410ae",
      "40cd9171d1de405cb42aac5170a817e2",
      "7bdf237d65a14bb9bbe75580f58d1409"
     ]
    },
    "id": "RGgUmqIwxaEK",
    "outputId": "d05f9e0b-aa3d-4536-a8cd-033f12e17d0e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "\n",
    "clip_model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "clip_model.eval()  # model in train mode by default, impacts some models with BatchNorm or stochastic depth active\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjyzDJ4gyLic",
    "outputId": "20f80847-e427-4aa7-8498-2010e439bc7b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_row_recall_at_k(confusion_matrix, k=5):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of rows where the diagonal element is among the top K values.\n",
    "\n",
    "    Parameters:\n",
    "    confusion_matrix : array-like\n",
    "        A square confusion matrix where rows represent actual classes\n",
    "        and columns represent predicted classes\n",
    "    k : int, optional (default=5)\n",
    "        Number of top values to consider\n",
    "\n",
    "    Returns:\n",
    "    float: Percentage (0-1) of rows where diagonal element is in top K values\n",
    "    dict: Additional metrics including per-row results and ranks\n",
    "    \"\"\"\n",
    "    # Convert input to numpy array if it isn't already\n",
    "    conf_matrix = np.array(confusion_matrix)\n",
    "\n",
    "    # Verify it's a square matrix\n",
    "    if conf_matrix.shape[0] != conf_matrix.shape[1]:\n",
    "        raise ValueError(\"Confusion matrix must be square\")\n",
    "\n",
    "    # Verify k is valid\n",
    "    if k > conf_matrix.shape[1]:\n",
    "        raise ValueError(f\"k ({k}) cannot be larger than matrix width ({conf_matrix.shape[1]})\")\n",
    "\n",
    "    correct_rows = 0\n",
    "    total_rows = conf_matrix.shape[0]\n",
    "\n",
    "    # Store detailed results for each row\n",
    "    row_results = []\n",
    "    diagonal_ranks = []\n",
    "\n",
    "    for i in range(total_rows):\n",
    "        # Get the diagonal value for this row\n",
    "        diagonal_value = conf_matrix[i, i]\n",
    "\n",
    "        # Sort row values in descending order and get ranks\n",
    "        row_sorted = np.sort(conf_matrix[i])[::-1]\n",
    "\n",
    "        # Find rank of diagonal value (handling ties optimistically)\n",
    "        # We use >= to give the best possible rank in case of ties\n",
    "        rank = np.sum(conf_matrix[i] >= diagonal_value)\n",
    "        diagonal_ranks.append(rank)\n",
    "\n",
    "        # Check if diagonal value is in top k\n",
    "        is_in_top_k = rank <= k\n",
    "        row_results.append(is_in_top_k)\n",
    "\n",
    "        if is_in_top_k:\n",
    "            correct_rows += 1\n",
    "\n",
    "    recall_at_k = correct_rows / total_rows\n",
    "\n",
    "    # Compile detailed metrics\n",
    "    metrics = {\n",
    "        'recall_at_k': recall_at_k,\n",
    "        'row_results': row_results,\n",
    "        'diagonal_ranks': diagonal_ranks,\n",
    "        'correct_rows': correct_rows,\n",
    "        'total_rows': total_rows\n",
    "    }\n",
    "\n",
    "    return recall_at_k, metrics\n",
    "\n",
    "# test\n",
    "# Example confusion matrix\n",
    "matrix = [\n",
    "    [80, 10, 90, 20],  # Row 0: diagonal value 80 is 2nd highest\n",
    "    [5,  95, 10, 15],  # Row 1: diagonal value 95 is highest\n",
    "    [10, 5,  40, 50],  # Row 2: diagonal value 40 is 2nd highest\n",
    "    [20, 15, 30, 60]   # Row 3: diagonal value 60 is highest\n",
    "]\n",
    "\n",
    "recall, metrics = get_row_recall_at_k(matrix, k=2)\n",
    "\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTgMB2IT07Ob"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_row_diagonal_accuracy(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of rows where the diagonal element is the highest value.\n",
    "\n",
    "    Parameters:\n",
    "    confusion_matrix : array-like\n",
    "        A square confusion matrix where rows represent actual classes\n",
    "        and columns represent predicted classes\n",
    "\n",
    "    Returns:\n",
    "    float: Percentage (0-1) of rows where diagonal element is highest\n",
    "    \"\"\"\n",
    "    # Convert input to numpy array if it isn't already\n",
    "    conf_matrix = np.array(confusion_matrix)\n",
    "\n",
    "    # Verify it's a square matrix\n",
    "    if conf_matrix.shape[0] != conf_matrix.shape[1]:\n",
    "        raise ValueError(\"Confusion matrix must be square\")\n",
    "\n",
    "    correct_rows = 0\n",
    "    total_rows = conf_matrix.shape[0]\n",
    "\n",
    "    # For each row, check if diagonal element is the maximum\n",
    "    for i in range(total_rows):\n",
    "        if conf_matrix[i, i] >= np.max(conf_matrix[i]):  # >= handles case where diagonal equals another value\n",
    "            correct_rows += 1\n",
    "\n",
    "    return correct_rows / total_rows\n",
    "\n",
    "def load_descriptions():\n",
    "    \"\"\"\n",
    "    Load descriptions from descriptions.txt into a list where the index matches the description.\n",
    "    Skips the header row.\n",
    "\n",
    "    Returns:\n",
    "        list: List of descriptions where index i contains the description for item i\n",
    "    \"\"\"\n",
    "    descriptions = []\n",
    "    with open(\"/content/drive/MyDrive/audiocap_processed/merged_output.csv\", \"r\") as f:\n",
    "        next(f)  # Skip the header row\n",
    "        for line in f:\n",
    "            idx, desc = line.strip().split(',', 1)\n",
    "            # Make sure list is long enough\n",
    "            while len(descriptions) <= int(idx):\n",
    "                descriptions.append(None)\n",
    "            descriptions[int(idx)] = desc\n",
    "    return descriptions\n",
    "\n",
    "def generate_uniform_hypersphere(m, n):\n",
    "    \"\"\"\n",
    "    Generate m points uniformly distributed on an n-dimensional unit hypersphere.\n",
    "\n",
    "    This implementation uses the fact that normalizing vectors sampled from a\n",
    "    multivariate normal distribution results in uniform distribution on the sphere.\n",
    "\n",
    "    Parameters:\n",
    "    m (int): Number of vectors to generate\n",
    "    n (int): Dimension of the space\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Array of shape (m, n) containing m n-dimensional unit vectors\n",
    "    \"\"\"\n",
    "    # Generate random vectors from standard normal distribution\n",
    "    vectors = np.random.normal(0, 1, (m, n))\n",
    "\n",
    "    # Normalize each vector to lie on unit hypersphere\n",
    "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "    uniform_vectors = vectors / norms\n",
    "\n",
    "    return torch.tensor(uniform_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZI3U171P0Bd0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_test_set():\n",
    "  descriptions = load_descriptions()\n",
    "\n",
    "  # Find which indices actually have both image and audio files\n",
    "  valid_indices = []\n",
    "  valid_image_indices = []\n",
    "  for i in range(len(descriptions)):\n",
    "      audio_path = f'/content/drive/MyDrive/audiocap_processed/audio/audio_{i}.wav'\n",
    "      image_path = f'/content/drive/MyDrive/audiocap_processed/images/image_{i}.jpg'\n",
    "      if os.path.exists(audio_path):\n",
    "          valid_indices.append(i)\n",
    "      if os.path.exists(image_path):\n",
    "          valid_image_indices.append(i)\n",
    "\n",
    "  # Shuffle the valid indices\n",
    "  shuffled_valid_indices = np.random.permutation(valid_indices)\n",
    "\n",
    "  # Take only N items (or all if less than N available)\n",
    "  N = 25\n",
    "  n_available = min(N, len(shuffled_valid_indices))\n",
    "  selected_indices = shuffled_valid_indices[:n_available]\n",
    "\n",
    "  # Create the path lists using only valid indices\n",
    "  # image_paths = [f'/content/image_{i}.jpg' for i in selected_indices]\n",
    "  audio_paths = [f'/content/drive/MyDrive/audiocap_processed/audio/audio_{i}.wav' for i in selected_indices]\n",
    "  image_paths = [f'/content/drive/MyDrive/audiocap_processed/images/image_{i}.jpg' for i in valid_image_indices]\n",
    "  text_list = [descriptions[i] for i in selected_indices]\n",
    "\n",
    "  print(f\"Found {len(valid_indices)} valid pairs, using {n_available}\")\n",
    "\n",
    "  return audio_paths, text_list, image_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsYsRGpEp4LS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def create_image_set():\n",
    "  valid_indices = []\n",
    "  valid_image_indices = []\n",
    "  for i in range(1000):\n",
    "      image_path = f'/content/image_{i}.jpg'\n",
    "      if os.path.exists(image_path):\n",
    "          valid_image_indices.append(i)\n",
    "\n",
    "  image_paths = [f'/content/image_{i}.jpg' for i in valid_image_indices]\n",
    "\n",
    "  return image_paths\n",
    "\n",
    "def create_test_set2(num_samples=25, csv_path='/content/filename_mapping.csv'):\n",
    "    \"\"\"\n",
    "    Extract random samples of audio filenames and their corresponding captions.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the filename_mapping.csv\n",
    "        num_samples (int): Number of samples to extract\n",
    "        seed (int): Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        tuple: (list of audio filenames, list of corresponding captions)\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Ensure we don't try to get more samples than available\n",
    "    num_samples = min(num_samples, len(df))\n",
    "\n",
    "    # Randomly sample the dataframe\n",
    "    sampled_df = df.sample(n=num_samples)\n",
    "\n",
    "    # Extract lists\n",
    "    audio_paths = [f'/content/{file}' for file in sampled_df['new_filename'].tolist()]\n",
    "    text_list = sampled_df['caption'].tolist()\n",
    "\n",
    "    return audio_paths, text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9h0GC5YrrHYC",
    "outputId": "de1003f5-148f-4696-9d9e-ba342f6352bd"
   },
   "outputs": [],
   "source": [
    "audio_paths, text_list, image_paths = create_test_set()\n",
    "# image_paths = create_image_set()\n",
    "# audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OlvMLnu0_lt"
   },
   "outputs": [],
   "source": [
    "def get_embeddings_imagebind(image_paths=None, audio_paths=None, text_list=None):\n",
    "    embeddings = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Process vision if provided\n",
    "        if image_paths:\n",
    "            vision_embeddings = []\n",
    "            for img_path in image_paths:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                inputs = {\n",
    "                    ModalityType.VISION: data.load_and_transform_vision_data([img_path], device)\n",
    "                }\n",
    "\n",
    "                single_embedding = ib_model(inputs)\n",
    "                vision_embeddings.append(single_embedding[ModalityType.VISION].cpu())\n",
    "\n",
    "                del inputs, single_embedding\n",
    "\n",
    "            embeddings[ModalityType.VISION] = torch.cat(vision_embeddings, dim=0)\n",
    "            del vision_embeddings\n",
    "\n",
    "        # Process audio if provided\n",
    "        if audio_paths:\n",
    "            audio_embeddings = []\n",
    "            for audio_path in audio_paths:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                inputs = {\n",
    "                    ModalityType.AUDIO: data.load_and_transform_audio_data([audio_path], device)\n",
    "                }\n",
    "\n",
    "                single_embedding = ib_model(inputs)\n",
    "                audio_embeddings.append(single_embedding[ModalityType.AUDIO].cpu())\n",
    "\n",
    "                del inputs, single_embedding\n",
    "\n",
    "            embeddings[ModalityType.AUDIO] = torch.cat(audio_embeddings, dim=0)\n",
    "            del audio_embeddings\n",
    "\n",
    "        # Process text if provided\n",
    "        if text_list:\n",
    "            text_embeddings = []\n",
    "            for text in text_list:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                inputs = {\n",
    "                    ModalityType.TEXT: data.load_and_transform_text([text], device)\n",
    "                }\n",
    "\n",
    "                single_embedding = ib_model(inputs)\n",
    "                text_embeddings.append(single_embedding[ModalityType.TEXT].cpu())\n",
    "\n",
    "                del inputs, single_embedding\n",
    "\n",
    "            embeddings[ModalityType.TEXT] = torch.cat(text_embeddings, dim=0)\n",
    "            del text_embeddings\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def get_embeddings_clip(image_paths, text_list):\n",
    "  images = []\n",
    "  for img_path in image_paths:\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    images.append(preprocess(img))\n",
    "  images = torch.stack(images).float()\n",
    "\n",
    "  texts = tokenizer(text_list)\n",
    "\n",
    "  with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    image_features = clip_model.encode_image(images)\n",
    "    text_features = clip_model.encode_text(texts)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "  return image_features, text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4G2XopUm3HS",
    "outputId": "f9833acd-f17c-458c-e8b7-7a49e05dda25"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# audio_paths, text_list, image_paths = create_test_set()\n",
    "\n",
    "# def compute_embeddings(audio_paths, text_list, image_paths):\n",
    "#   # get embeddings\n",
    "#   imagebind_embeddings = get_embeddings_imagebind(image_paths, audio_paths, text_list)\n",
    "#   clip_image_embeddings, clip_text_embeddings = get_embeddings_clip(image_paths, text_list)\n",
    "\n",
    "#   PHI_B1 = imagebind_embeddings[ModalityType.VISION].cpu()\n",
    "#   PHI_B2 = clip_image_embeddings.cpu()\n",
    "#   print(f'PHI_B1: {PHI_B1.shape}')\n",
    "#   print(f'PHI_B2: {PHI_B2.shape}')\n",
    "\n",
    "\n",
    "#   # get imagebind (audio) embedding and clip (language) embedding for the test pairs\n",
    "#   embeddings_A = imagebind_embeddings[ModalityType.AUDIO].cpu()\n",
    "#   embeddings_C= clip_text_embeddings\n",
    "#   print(f'embeddings_A: {embeddings_A.shape}')\n",
    "#   print(f'embeddings_C: {embeddings_C.shape}')\n",
    "\n",
    "#   # imagebind (text) for direct eval\n",
    "#   embeddings_B = imagebind_embeddings[ModalityType.TEXT].cpu()\n",
    "\n",
    "#   return PHI_B1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDCuhBUYr3Em",
    "outputId": "80ebf53d-1394-4225-dc07-b8f0930048e9"
   },
   "outputs": [],
   "source": [
    "audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTpwi_Zgz2mK",
    "outputId": "3da5c8f6-9adc-4e8d-87fb-121a355c126f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def get_phi_matrices(image_paths):\n",
    "    \"\"\"Get PHI_B1 and PHI_B2 matrices from imagebind and CLIP image embeddings\"\"\"\n",
    "    # Get embeddings for PHI matrices\n",
    "    imagebind_embeddings = get_embeddings_imagebind(image_paths=image_paths)\n",
    "    clip_image_embeddings, _ = get_embeddings_clip(image_paths, [\"fake\"])\n",
    "\n",
    "    # Extract PHI matrices\n",
    "    PHI_B1 = imagebind_embeddings[ModalityType.VISION].cpu()\n",
    "    PHI_B2 = clip_image_embeddings.cpu()\n",
    "\n",
    "    print(f'PHI_B1: {PHI_B1.shape}')\n",
    "    print(f'PHI_B2: {PHI_B2.shape}')\n",
    "\n",
    "    return PHI_B1, PHI_B2\n",
    "\n",
    "def get_test_embeddings(audio_paths, text_list):\n",
    "    \"\"\"Get embeddings for the test pairs (A, B, C)\"\"\"\n",
    "    # Get embeddings from both models\n",
    "    imagebind_embeddings = get_embeddings_imagebind(audio_paths=audio_paths, text_list=text_list)\n",
    "    _, clip_text_embeddings = get_embeddings_clip([\"/content/drive/MyDrive/audiocap_processed/images/image_1.jpg\"], text_list)\n",
    "\n",
    "    # Extract required embeddings\n",
    "    embeddings_A = imagebind_embeddings[ModalityType.AUDIO].cpu()  # imagebind audio\n",
    "    embeddings_B = imagebind_embeddings[ModalityType.TEXT].cpu()   # imagebind text\n",
    "    embeddings_C = clip_text_embeddings                           # CLIP text\n",
    "\n",
    "    print(f'embeddings_A: {embeddings_A.shape}')\n",
    "    print(f'embeddings_B: {embeddings_B.shape}')\n",
    "    print(f'embeddings_C: {embeddings_C.shape}')\n",
    "\n",
    "    return embeddings_A, embeddings_B, embeddings_C\n",
    "\n",
    "def compute_embeddings(audio_paths, text_list, image_paths):\n",
    "    \"\"\"Main function that computes all required embeddings\"\"\"\n",
    "    # Get PHI matrices\n",
    "    PHI_B1, PHI_B2 = get_phi_matrices(image_paths)\n",
    "\n",
    "    # Get test embeddings\n",
    "    embeddings_A, embeddings_B, embeddings_C = get_test_embeddings(audio_paths, text_list)\n",
    "\n",
    "    return PHI_B1, PHI_B2, embeddings_A, embeddings_B, embeddings_C\n",
    "\n",
    "# Example usage\n",
    "audio_paths, text_list, image_paths = create_test_set()\n",
    "# image_paths = create_image_set()\n",
    "# PHI_B1, PHI_B2, embeddings_A, embeddings_B, embeddings_C = compute_embeddings(audio_paths, text_list, image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3s4E8SauRk6",
    "outputId": "8d667172-cd3b-4eaf-82fc-333a4e9137dc"
   },
   "outputs": [],
   "source": [
    "audio_paths, text_list, image_paths = create_test_set()\n",
    "\n",
    "PHI_B1, PHI_B2 = get_phi_matrices(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBgATJd9yEiS",
    "outputId": "9c42077a-e02f-4769-d6de-777ca6432eca"
   },
   "outputs": [],
   "source": [
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DwdqoF-vuU5Y",
    "outputId": "a5683951-beff-4eac-e4a7-255f869759d6"
   },
   "outputs": [],
   "source": [
    "embeddings_A, embeddings_B, embeddings_C = get_test_embeddings(audio_paths, text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8bf47cecd6f54b25a8b296ad0a3f2d5c",
      "d31ac8b53a2147c3869fa5389f553ece",
      "bfa113efc0654288ae0dce3dc7f1b300",
      "680e45fa9b0e44069882aecad311f234",
      "bdba00ddd5384a2f80b4ac0e7a9de912",
      "6315123cdbcd40cda3df3f010ade70ff",
      "7ede769ab207456ca7f623006aea4ce9",
      "770a6a45aab64b309195423bd76a83f6",
      "61fe9bf76f534e82a5e08af98c38940e",
      "c1f0452a9ef24413abec2a0651e8bd17",
      "00983322968f47b98dc5ae187fdba04a"
     ]
    },
    "id": "XMlCmBk7JSl2",
    "outputId": "c0619a62-d0e2-4c3e-e1f7-5279b59b5ae7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import laion_clap\n",
    "\n",
    "# quantization\n",
    "def int16_to_float32(x):\n",
    "    return (x / 32767.0).astype(np.float32)\n",
    "\n",
    "\n",
    "def float32_to_int16(x):\n",
    "    x = np.clip(x, a_min=-1., a_max=1.)\n",
    "    return (x * 32767.).astype(np.int16)\n",
    "\n",
    "clap_model = laion_clap.CLAP_Module(enable_fusion=False)\n",
    "clap_model.load_ckpt() # download the default pretrained checkpoint.\n",
    "\n",
    "\n",
    "# Directly get audio embeddings from audio files\n",
    "audio_file = [\n",
    "    '/content/drive/MyDrive/audiocap_processed/audio/audio_1.wav',\n",
    "]\n",
    "audio_embed = clap_model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=False)\n",
    "print(audio_embed[:,-20:])\n",
    "print(audio_embed.shape)\n",
    "\n",
    "# Get text embedings from texts:\n",
    "text_data = [\"I love the contrastive learning\", \"I love the pretrain model\"]\n",
    "text_embed = clap_model.get_text_embedding(text_data)\n",
    "print(text_embed)\n",
    "print(text_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvdb0gf83puE"
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_trial(PHI_B1, PHI_B2, k, tau1=5, tau2=5, M=512):\n",
    "    audio_paths, text_list, image_paths = create_test_set()\n",
    "    embeddings_A, embeddings_B, embeddings_C = get_test_embeddings(audio_paths, text_list)\n",
    "\n",
    "    clap_embeddings_A = clap_model.get_audio_embedding_from_filelist(x = audio_paths)\n",
    "    clap_embeddings_B = clap_model.get_text_embedding(text_list)\n",
    "\n",
    "    direct_grid = embeddings_A @ embeddings_B.T\n",
    "    acc_direct = get_row_diagonal_accuracy(direct_grid)\n",
    "\n",
    "    clap_direct_grid = clap_embeddings_A @ clap_embeddings_B.T\n",
    "    clap_acc_direct = get_row_diagonal_accuracy(clap_direct_grid)\n",
    "\n",
    "    partial_PHI_B1 = PHI_B1[:M]\n",
    "    partial_PHI_B2 = PHI_B2[:M]\n",
    "\n",
    "    # Move all data to GPU at once\n",
    "    embeddings_A_gpu = embeddings_A.cuda()  # [A, d1]\n",
    "    embeddings_C_gpu = embeddings_C.cuda()  # [C, d2]\n",
    "    partial_PHI_B1_gpu = partial_PHI_B1.float().cuda()  # [M, d1]\n",
    "    partial_PHI_B2_gpu = partial_PHI_B2.float().cuda()  # [M, d2]\n",
    "\n",
    "    # Compute the terms separately using batch matrix multiplication\n",
    "    term1 = embeddings_A_gpu @ partial_PHI_B1_gpu.T / tau1  # [A, M]\n",
    "    term2 = partial_PHI_B2_gpu @ embeddings_C_gpu.T / tau2  # [M, C]\n",
    "\n",
    "    # Combine terms and sum over M dimension\n",
    "    grid_lse = torch.sum(torch.exp(term1.unsqueeze(2) + term2.unsqueeze(0)), dim=1)  # [A, C]\n",
    "\n",
    "    # Move result back to CPU and check for inf values\n",
    "    grid_lse = grid_lse.cpu().numpy()\n",
    "\n",
    "    if np.any(np.isinf(grid_lse)):\n",
    "        print(f\"WARNING: Infinite values detected in grid_lse with tau1={tau1}, tau2={tau2}\")\n",
    "        print(\"Consider using smaller tau values to prevent numerical overflow\")\n",
    "        # Optionally print positions of inf values\n",
    "        inf_positions = np.where(np.isinf(grid_lse))\n",
    "        print(f\"Infinite values found at positions: {inf_positions}\")\n",
    "\n",
    "    acc_lse = get_row_diagonal_accuracy(grid_lse)\n",
    "    print(f'acc_direct: {acc_direct}')\n",
    "    print(f'acc_lse: {acc_lse}')\n",
    "    print(f'acc_clap: {clap_acc_direct}')\n",
    "\n",
    "    return acc_direct, acc_lse, clap_acc_direct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-EIb3zR23cE",
    "outputId": "18fdc097-b0b3-41ed-8c91-cc73bb1e9c41"
   },
   "outputs": [],
   "source": [
    "run_trial(PHI_B1, PHI_B2, k=10, tau1=0.25, tau2=0.25, M=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "XTMxLBDLHxtP",
    "outputId": "b5406080-dd3d-416b-d481-5d1c31c7c3f5"
   },
   "outputs": [],
   "source": [
    "print(grid_lse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgR1roaLvFMY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def run_multiple_trials(n_trials, k=10, tau1=1, tau2=1, M=512):\n",
    "    # Store results\n",
    "    direct_results = []\n",
    "    lse_results = []\n",
    "    clap_results = []\n",
    "\n",
    "    # Run trials\n",
    "    for i in range(n_trials):\n",
    "        print(f\"Running trial {i+1}/{n_trials}\")\n",
    "        acc_direct, acc_lse, acc_clap = run_trial(PHI_B1, PHI_B2, k=k, tau1=tau1, tau2=tau2, M=M)\n",
    "        # if acc_lse > 0.05:  # Keep the existing filter\n",
    "        direct_results.append(acc_direct)\n",
    "        lse_results.append(acc_lse)\n",
    "        clap_results.append(acc_clap)\n",
    "\n",
    "    # Calculate means and confidence intervals\n",
    "    direct_mean = np.mean(direct_results)\n",
    "    lse_mean = np.mean(lse_results)\n",
    "    clap_mean = np.mean(clap_results)\n",
    "\n",
    "    # 95% confidence intervals\n",
    "    direct_ci = stats.sem(direct_results) * stats.t.ppf((1 + 0.95) / 2, len(direct_results)-1)\n",
    "    lse_ci = stats.sem(lse_results) * stats.t.ppf((1 + 0.95) / 2, len(lse_results)-1)\n",
    "    clap_ci = stats.sem(clap_results) * stats.t.ppf((1 + 0.95) / 2, len(clap_results)-1)\n",
    "\n",
    "    # Create bar plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # Increased width to accommodate third bar\n",
    "\n",
    "    # Plot bars\n",
    "    x = np.arange(3)  # Three bars now\n",
    "    bars = ax.bar(x, [direct_mean, lse_mean, clap_mean],\n",
    "                 yerr=[direct_ci, lse_ci, clap_ci],\n",
    "                 capsize=5, width=0.4,\n",
    "                 color=['lightblue', 'lightgreen', 'lightcoral'])\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['Direct', 'LSE', 'CLAP'])\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title(f'Accuracy Comparison (n={n_trials} trials)')\n",
    "\n",
    "    # Add value labels on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "    # Store numerical results\n",
    "    results = {\n",
    "        'direct': {\n",
    "            'mean': direct_mean,\n",
    "            'ci': direct_ci,\n",
    "            'all_values': direct_results\n",
    "        },\n",
    "        'lse': {\n",
    "            'mean': lse_mean,\n",
    "            'ci': lse_ci,\n",
    "            'all_values': lse_results\n",
    "        },\n",
    "        'clap': {\n",
    "            'mean': clap_mean,\n",
    "            'ci': clap_ci,\n",
    "            'all_values': clap_results\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results, fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eDt9wq7dAbx4",
    "outputId": "021603a0-4836-44ac-d8d1-9b1b0cc634fa"
   },
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "tau_vals = [0.25, 0.5, 1., 2.]\n",
    "\n",
    "results, fig = run_multiple_trials(n_trials=100, k=1, tau1=0.1, tau2=0.1, M=580)\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(f\"Direct: {results['direct']['mean']:.3f} ± {results['direct']['ci']:.3f}\")\n",
    "print(f\"LSE: {results['lse']['mean']:.3f} ± {results['lse']['ci']:.3f}\")\n",
    "print(f\"CLAP: {results['clap']['mean']:.3f} ± {results['clap']['ci']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vLSywAkROYnQ",
    "outputId": "d33225ec-cc41-447c-94fc-350c5db24672"
   },
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "# tau_vals = [0.25, 0.5, 1., 2.]\n",
    "\n",
    "M_vals = [4, 16, 64, 128, 256, 512, 580]\n",
    "\n",
    "for M in M_vals:\n",
    "  print(f'Running for M = {M}')\n",
    "  results, fig = run_multiple_trials(n_trials=5, k=1, tau1=0.25, tau2=0.25, M=M)\n",
    "  plt.show()\n",
    "\n",
    "  # Print detailed results\n",
    "  print(\"\\nDetailed Results:\")\n",
    "  print(f\"Direct: {results['direct']['mean']:.3f} ± {results['direct']['ci']:.3f}\")\n",
    "  print(f\"LSE: {results['lse']['mean']:.3f} ± {results['lse']['ci']:.3f}\")\n",
    "  print(f\"CLAP: {results['clap']['mean']:.3f} ± {results['clap']['ci']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "p61kkMGbTJnM",
    "outputId": "38249883-f33c-4393-b671-70cd72bc187b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compare_M_values():\n",
    "    M_vals = [4, 16, 64, 128, 256, 512, 580]\n",
    "    results_list = []\n",
    "\n",
    "    # Run trials for each M value\n",
    "    print(\"Running trials for different M values...\")\n",
    "    for M in tqdm(M_vals):\n",
    "        print(f'\\nRunning for M = {M}')\n",
    "        results, _ = run_multiple_trials(n_trials=10, k=1, tau1=0.1, tau2=0.1, M=M)\n",
    "        results_list.append({\n",
    "            'M': M,\n",
    "            'direct': results['direct'],\n",
    "            'lse': results['lse'],\n",
    "            'clap': results['clap']\n",
    "        })\n",
    "        print(f\"Direct: {results['direct']['mean']:.3f} ± {results['direct']['ci']:.3f}\")\n",
    "        print(f\"LSE: {results['lse']['mean']:.3f} ± {results['lse']['ci']:.3f}\")\n",
    "        print(f\"CLAP: {results['clap']['mean']:.3f} ± {results['clap']['ci']:.3f}\")\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Extract data for plotting\n",
    "    M_values = [r['M'] for r in results_list]\n",
    "    lse_means = [r['lse']['mean'] for r in results_list]\n",
    "    lse_cis = [r['lse']['ci'] for r in results_list]\n",
    "    direct_means = [r['direct']['mean'] for r in results_list]\n",
    "    clap_means = [r['clap']['mean'] for r in results_list]\n",
    "\n",
    "    # Plot LSE with error bars\n",
    "    ax.errorbar(M_values, lse_means, yerr=lse_cis, label='LSE',\n",
    "                marker='o', capsize=5, linestyle='-', color='blue')\n",
    "\n",
    "    # Plot Direct and CLAP as horizontal lines\n",
    "    ax.axhline(y=direct_means[0], label='Direct', color='red', linestyle='--')\n",
    "    ax.axhline(y=clap_means[0], label='CLAP', color='green', linestyle='--')\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_xscale('log', base=2)  # Use log scale for M values\n",
    "    ax.set_xlabel('M (log scale)')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Performance Comparison Across Different M Values')\n",
    "    ax.grid(True, which='both', linestyle='--', alpha=0.7)\n",
    "    ax.legend()\n",
    "\n",
    "    # Add value labels for Direct and CLAP\n",
    "    plt.text(M_values[-1], direct_means[0], f'Direct: {direct_means[0]:.3f}',\n",
    "             verticalalignment='bottom')\n",
    "    plt.text(M_values[-1], clap_means[0], f'CLAP: {clap_means[0]:.3f}',\n",
    "             verticalalignment='bottom')\n",
    "\n",
    "    # Print detailed results table\n",
    "    print(\"\\nDetailed Results Table:\")\n",
    "    print(\"M\\tLSE\\t\\tDirect\\t\\tCLAP\")\n",
    "    print(\"-\" * 50)\n",
    "    for r in results_list:\n",
    "        print(f\"{r['M']}\\t{r['lse']['mean']:.3f}±{r['lse']['ci']:.3f}\\t\"\n",
    "              f\"{r['direct']['mean']:.3f}±{r['direct']['ci']:.3f}\\t\"\n",
    "              f\"{r['clap']['mean']:.3f}±{r['clap']['ci']:.3f}\")\n",
    "\n",
    "    return results_list, fig\n",
    "\n",
    "# Run comparison\n",
    "results_list, fig = compare_M_values()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZkEbI1M0Bw-V",
    "outputId": "c88dc39c-3880-434e-b6c9-09c7156b1891"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def grid_search_taus():\n",
    "    # Define tau values to test\n",
    "    tau_vals = [0.25, 0.5]\n",
    "\n",
    "    # Create all combinations of tau1 and tau2\n",
    "    tau_combinations = list(itertools.product(tau_vals, tau_vals))\n",
    "\n",
    "    # Store results\n",
    "    results_grid = []\n",
    "\n",
    "    # Run trials for each combination\n",
    "    print(\"Running grid search...\")\n",
    "    for tau1, tau2 in tqdm(tau_combinations):\n",
    "        results, _ = run_multiple_trials(n_trials=5, k=1, tau1=tau1, tau2=tau2)\n",
    "        results_grid.append({\n",
    "            'tau1': tau1,\n",
    "            'tau2': tau2,\n",
    "            'lse_mean': results['lse']['mean'],\n",
    "            'lse_ci': results['lse']['ci']\n",
    "        })\n",
    "\n",
    "    # Find best combination\n",
    "    best_result = max(results_grid, key=lambda x: x['lse_mean'])\n",
    "\n",
    "    # Create heatmap\n",
    "    tau_matrix = np.zeros((len(tau_vals), len(tau_vals)))\n",
    "    for result in results_grid:\n",
    "        i = tau_vals.index(result['tau1'])\n",
    "        j = tau_vals.index(result['tau2'])\n",
    "        tau_matrix[i, j] = result['lse_mean']\n",
    "\n",
    "    # Plot heatmap\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    im = ax.imshow(tau_matrix, cmap='viridis')\n",
    "\n",
    "    # Add colorbar\n",
    "    plt.colorbar(im)\n",
    "\n",
    "    # Add labels\n",
    "    ax.set_xticks(np.arange(len(tau_vals)))\n",
    "    ax.set_yticks(np.arange(len(tau_vals)))\n",
    "    ax.set_xticklabels(tau_vals)\n",
    "    ax.set_yticklabels(tau_vals)\n",
    "\n",
    "    # Add tau values as labels\n",
    "    for i in range(len(tau_vals)):\n",
    "        for j in range(len(tau_vals)):\n",
    "            text = ax.text(j, i, f'{tau_matrix[i, j]:.3f}',\n",
    "                         ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    plt.xlabel('tau2')\n",
    "    plt.ylabel('tau1')\n",
    "    plt.title('LSE Accuracy for Different Tau Values')\n",
    "\n",
    "    return results_grid, best_result, fig\n",
    "\n",
    "# Run grid search\n",
    "results_grid, best_result, fig = grid_search_taus()\n",
    "\n",
    "# Print results\n",
    "print(\"\\nGrid Search Results:\")\n",
    "print(f\"Best configuration:\")\n",
    "print(f\"tau1: {best_result['tau1']}\")\n",
    "print(f\"tau2: {best_result['tau2']}\")\n",
    "print(f\"LSE accuracy: {best_result['lse_mean']:.3f} ± {best_result['lse_ci']:.3f}\")\n",
    "\n",
    "# Show heatmap\n",
    "plt.show()\n",
    "\n",
    "# Print all results in a sorted format\n",
    "print(\"\\nAll Results (sorted by accuracy):\")\n",
    "sorted_results = sorted(results_grid, key=lambda x: x['lse_mean'], reverse=True)\n",
    "for result in sorted_results:\n",
    "    print(f\"tau1: {result['tau1']}, tau2: {result['tau2']}, \"\n",
    "          f\"accuracy: {result['lse_mean']:.3f} ± {result['lse_ci']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSj8CvuZGv89",
    "outputId": "d5ac6f1e-b9c6-4ae4-e698-e0e7192955ee"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Directly get audio embeddings from audio files\n",
    "audio_file = [\n",
    "    '/content/audio_496.wav',\n",
    "]\n",
    "audio_embed = clap_model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=False)\n",
    "print(audio_embed[:,-20:])\n",
    "print(audio_embed.shape)\n",
    "\n",
    "# Get text embedings from texts:\n",
    "text_data = [\"I love the contrastive learning\", \"I love the pretrain model\"]\n",
    "text_embed = clap_model.get_text_embedding(text_data)\n",
    "print(text_embed)\n",
    "print(text_embed.shape)\n",
    "\n",
    "# # Get text embedings from texts, but return torch tensor:\n",
    "# text_data = [\"I love the contrastive learning\", \"I love the pretrain model\"]\n",
    "# text_embed = model.get_text_embedding(text_data, use_tensor=True)\n",
    "# print(text_embed)\n",
    "# print(text_embed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vO5ZaDRpukob"
   },
   "outputs": [],
   "source": [
    "\n",
    "for M in mc_sizes:\n",
    "  partial_PHI_B1 = PHI_B1[:M]\n",
    "  partial_PHI_B2 = PHI_B2[:M]\n",
    "  # partial_PHI_B1 = generate_uniform_hypersphere(M, partial_PHI_B1.shape[1])\n",
    "  # partial_PHI_B2 = generate_uniform_hypersphere(M, partial_PHI_B2.shape[1])\n",
    "  grid_lse = np.zeros((len(audio_paths), len(audio_paths)))\n",
    "  for i in range(embeddings_A.shape[0]):\n",
    "    for j in range(embeddings_C.shape[0]):\n",
    "      for phi1, phi2 in zip(partial_PHI_B1, partial_PHI_B2):\n",
    "        grid_lse[i, j] += torch.exp(embeddings_A[i] @ phi1.T.float() / tau + phi2.float() @ embeddings_C[j].T / tau).detach().cpu().numpy()\n",
    "\n",
    "  acc_lse = get_row_diagonal_accuracy(grid_lse)\n",
    "  print(f'Accuracy for M = {M}: {acc_lse}')\n",
    "  plt.imshow(grid_lse)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pVY3x1frva_",
    "outputId": "c46a7b9a-08ef-4e29-f7b6-d9b9205dcce1"
   },
   "outputs": [],
   "source": [
    "direct_grid = embeddings_A @ embeddings_B.T\n",
    "acc_direct = get_row_diagonal_accuracy(direct_grid)\n",
    "\n",
    "print(acc_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOfXkhHvsbJS",
    "outputId": "e5e35e7e-1ad9-4813-cafd-7a3dcc4beb14"
   },
   "outputs": [],
   "source": [
    "direct_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ku8shZTE1It8",
    "outputId": "14c89ebb-1a26-4fa8-a720-9a55360aa4b6"
   },
   "outputs": [],
   "source": [
    "mc_sizes = [4, 16, 64, 128, 256, 512]\n",
    "tau = 5\n",
    "\n",
    "for M in mc_sizes:\n",
    "  partial_PHI_B1 = PHI_B1[:M]\n",
    "  partial_PHI_B2 = PHI_B2[:M]\n",
    "  # partial_PHI_B1 = generate_uniform_hypersphere(M, partial_PHI_B1.shape[1])\n",
    "  # partial_PHI_B2 = generate_uniform_hypersphere(M, partial_PHI_B2.shape[1])\n",
    "  grid_lse = np.zeros((len(audio_paths), len(audio_paths)))\n",
    "  for i in range(embeddings_A.shape[0]):\n",
    "    for j in range(embeddings_C.shape[0]):\n",
    "      for phi1, phi2 in zip(partial_PHI_B1, partial_PHI_B2):\n",
    "        grid_lse[i, j] += torch.exp(embeddings_A[i] @ phi1.T.float() / tau + phi2.float() @ embeddings_C[j].T / tau).detach().cpu().numpy()\n",
    "\n",
    "  acc_lse = get_row_diagonal_accuracy(grid_lse)\n",
    "  print(f'Accuracy for M = {M}: {acc_lse}')\n",
    "  plt.imshow(grid_lse)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LG06YEk5qEhH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00983322968f47b98dc5ae187fdba04a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "00ad6be7495946068f7caf02676913b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ad70ac71b984582be1a712ae82410ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a38f63b85f94d1ab640b4d7120f9213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ef52e6441604606a2eb1a96e6eb4e39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40cd9171d1de405cb42aac5170a817e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41567679fc1448699707c486ffdc6df8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4aa0727423fb4ac6b26209e7b46e1ebf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "545c1bab284e47eaad977fde7c5f0013": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95a0b38d054843d5b29709a7a5a9c13e",
      "placeholder": "​",
      "style": "IPY_MODEL_d831ce4624cf42a283ddbac9d9cb9956",
      "value": " 4.47G/4.47G [00:19&lt;00:00, 228MB/s]"
     }
    },
    "61fe9bf76f534e82a5e08af98c38940e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6315123cdbcd40cda3df3f010ade70ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "680e45fa9b0e44069882aecad311f234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1f0452a9ef24413abec2a0651e8bd17",
      "placeholder": "​",
      "style": "IPY_MODEL_00983322968f47b98dc5ae187fdba04a",
      "value": " 499M/499M [00:02&lt;00:00, 209MB/s]"
     }
    },
    "701a4916b7c54e71b03a1b6eae6ef364": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73cf4181dbd74dfe9a64cac435449836": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "770a6a45aab64b309195423bd76a83f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bdf237d65a14bb9bbe75580f58d1409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ede769ab207456ca7f623006aea4ce9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bf47cecd6f54b25a8b296ad0a3f2d5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d31ac8b53a2147c3869fa5389f553ece",
       "IPY_MODEL_bfa113efc0654288ae0dce3dc7f1b300",
       "IPY_MODEL_680e45fa9b0e44069882aecad311f234"
      ],
      "layout": "IPY_MODEL_bdba00ddd5384a2f80b4ac0e7a9de912"
     }
    },
    "90ae8978682347b5aea74dc19318232b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ef52e6441604606a2eb1a96e6eb4e39",
      "max": 605219813,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ad70ac71b984582be1a712ae82410ae",
      "value": 605219813
     }
    },
    "95a0b38d054843d5b29709a7a5a9c13e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95ec030e403d4c03b28be937a674b0aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4aa0727423fb4ac6b26209e7b46e1ebf",
      "max": 4803584173,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e94fb3a33d394e5a8f286089b4b2c00a",
      "value": 4803584173
     }
    },
    "97f4659b1b604989b2dfb32d75d702cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73cf4181dbd74dfe9a64cac435449836",
      "placeholder": "​",
      "style": "IPY_MODEL_dc2ff2709de6483dbda8c6eaa3d8de74",
      "value": "open_clip_pytorch_model.bin: 100%"
     }
    },
    "b8903893d76f4b0e889e271de0027597": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ffb0fcdc3b75424f96946c90b1000116",
       "IPY_MODEL_95ec030e403d4c03b28be937a674b0aa",
       "IPY_MODEL_545c1bab284e47eaad977fde7c5f0013"
      ],
      "layout": "IPY_MODEL_701a4916b7c54e71b03a1b6eae6ef364"
     }
    },
    "bdba00ddd5384a2f80b4ac0e7a9de912": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfa113efc0654288ae0dce3dc7f1b300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_770a6a45aab64b309195423bd76a83f6",
      "max": 498818054,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_61fe9bf76f534e82a5e08af98c38940e",
      "value": 498818054
     }
    },
    "c1f0452a9ef24413abec2a0651e8bd17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd383711216e454f9ad8c8f88b4eb2b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_97f4659b1b604989b2dfb32d75d702cd",
       "IPY_MODEL_90ae8978682347b5aea74dc19318232b",
       "IPY_MODEL_d8ab476a464944caa26c3eb196518c78"
      ],
      "layout": "IPY_MODEL_00ad6be7495946068f7caf02676913b0"
     }
    },
    "d31ac8b53a2147c3869fa5389f553ece": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6315123cdbcd40cda3df3f010ade70ff",
      "placeholder": "​",
      "style": "IPY_MODEL_7ede769ab207456ca7f623006aea4ce9",
      "value": "model.safetensors: 100%"
     }
    },
    "d831ce4624cf42a283ddbac9d9cb9956": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d8ab476a464944caa26c3eb196518c78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40cd9171d1de405cb42aac5170a817e2",
      "placeholder": "​",
      "style": "IPY_MODEL_7bdf237d65a14bb9bbe75580f58d1409",
      "value": " 605M/605M [00:03&lt;00:00, 206MB/s]"
     }
    },
    "dc2ff2709de6483dbda8c6eaa3d8de74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e94fb3a33d394e5a8f286089b4b2c00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ffb0fcdc3b75424f96946c90b1000116": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41567679fc1448699707c486ffdc6df8",
      "placeholder": "​",
      "style": "IPY_MODEL_1a38f63b85f94d1ab640b4d7120f9213",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
